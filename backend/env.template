# FLUX.1-dev Backend Configuration
# Copy this file to .env and configure with your values

# ======================
# Required Configuration
# ======================

# Hugging Face API Token (REQUIRED)
# Get your token from: https://huggingface.co/settings/tokens
# Accept the FLUX.1-dev license at: https://huggingface.co/black-forest-labs/FLUX.1-dev
HUGGINGFACE_TOKEN=your_token_here

# ======================
# Server Configuration
# ======================

# Port to run the server on
FLUX_SERVER_PORT=8000

# Host to bind to (0.0.0.0 for all interfaces)
FLUX_HOST=0.0.0.0

# ======================
# Model Configuration
# ======================

# Model to load from Hugging Face
FLUX_MODEL_NAME=black-forest-labs/FLUX.1-dev

# Torch dtype (bfloat16 or float16)
# bfloat16 is recommended for H200 GPUs
FLUX_TORCH_DTYPE=bfloat16

# ======================
# Generation Defaults
# ======================

# Default image dimensions
FLUX_DEFAULT_HEIGHT=1024
FLUX_DEFAULT_WIDTH=1024

# Default guidance scale (higher = more prompt adherence)
FLUX_DEFAULT_GUIDANCE_SCALE=3.5

# Default number of inference steps (higher = better quality, slower)
FLUX_DEFAULT_NUM_STEPS=50

# Default max sequence length for the text encoder
FLUX_DEFAULT_MAX_SEQ_LENGTH=512

