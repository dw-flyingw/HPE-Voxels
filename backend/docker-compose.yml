services:
  flux-backend:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    container_name: flux-backend
    image: flux-backend:latest
    
    # GPU configuration - requires nvidia-docker runtime
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    # Environment variables from .env file
    env_file:
      - .env
    
    # Port mapping
    ports:
      - "${FLUX_SERVER_PORT:-8000}:${FLUX_SERVER_PORT:-8000}"
    
    # Volumes for model cache and data persistence
    volumes:
      # Cache Hugging Face models to avoid re-downloading (persistent volume)
      - huggingface-cache:/root/.cache/huggingface
      # Mount additional space for large model downloads
      - model-cache:/app/models
      # Optional: Mount local code for development
      # - ./flux_server.py:/app/flux_server.py
    
    # Restart policy
    restart: unless-stopped
    
    # Network
    networks:
      - flux-network
    
    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${FLUX_SERVER_PORT:-8000}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  huggingface-cache:
    driver: local
  model-cache:
    driver: local

networks:
  flux-network:
    driver: bridge

